{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install & Import libraries"
      ],
      "metadata": {
        "id": "oZlRIV5ehNco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Record the start time of the notebook\n",
        "import time\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "crdUbfMH5bAW"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ghcS7IS6vli",
        "outputId": "90b38303-a12e-42aa-d8fa-f57f3141031f"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q torch transformers tqdm scikit-learn pandas numpy rouge-score jiwer nltk sympy"
      ],
      "metadata": {
        "id": "_C1R0z7KhAby"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AdamW\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from jiwer import wer, cer\n",
        "from nltk.metrics.distance import jaro_winkler_similarity\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "nIBK_MdNgVHU"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and set device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "kd3RCrrFi6k6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8fdbe2-7806-4144-b7f5-1c8fa231476c"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess Data\n"
      ],
      "metadata": {
        "id": "JzpiAUaYhF1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "file_path = '/content/drive/My Drive/JobSeeking/Orfium/normalization_assesment_dataset_10k.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "DDOaNhxWlLsk"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess the text by:\n",
        "    - Lowercasing\n",
        "    - Removing special characters and numbers\n",
        "    - Stripping leading/trailing whitespaces\n",
        "    \"\"\"\n",
        "    if type(text) == float: # Handle NaN values\n",
        "      text = str(text)\n",
        "\n",
        "    text = text.lower()  # Lowercase text\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters and numbers\n",
        "    text = \" \".join(text.split())  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to the dataset\n",
        "df['raw_comp_writers_text'] = df['raw_comp_writers_text'].apply(preprocess_text)\n",
        "df['CLEAN_TEXT'] = df['CLEAN_TEXT'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "Fv1i2_z7ggCY"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train, validation, and test sets\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "# Extract inputs and targets for each split\n",
        "train_inputs, train_targets = train_df['raw_comp_writers_text'].tolist(), train_df['CLEAN_TEXT'].tolist()\n",
        "val_inputs, val_targets = val_df['raw_comp_writers_text'].tolist(), val_df['CLEAN_TEXT'].tolist()\n",
        "test_inputs, test_targets = test_df['raw_comp_writers_text'].tolist(), test_df['CLEAN_TEXT'].tolist()"
      ],
      "metadata": {
        "id": "r1NWLjdsmAI9"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer and Dataset Preparation"
      ],
      "metadata": {
        "id": "pYwWIjp_hWRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models Used\n",
        "\n",
        "1. **T5 (Text-to-Text Transfer Transformer)**\n",
        "* Model: t5-small\n",
        "* Description: T5 is a transformer model designed for a wide range of NLP tasks in a unified framework. It casts all NLP tasks as text-to-text problems, meaning that both inputs and outputs are in text format. This makes it highly versatile for tasks like text summarization, translation, and normalization.\n",
        "* Size: Small version (about 60 million parameters) offers a good balance between performance and efficiency for lightweight tasks.\n",
        "Use Case: Suitable for general text normalization tasks.\n",
        "\n",
        "2. **BART (Bidirectional and Auto-Regressive Transformers)**\n",
        "\n",
        "* Model: facebook/bart-base\n",
        "* Description: BART is a denoising autoencoder model designed for sequence-to-sequence tasks. It combines the best of both autoencoders and transformers, providing a strong model for text generation, summarization, and translation. It works by corrupting an input sequence and training the model to reconstruct it.\n",
        "* Size: bart-base is a medium-sized model with around 140 million parameters, offering a balance between speed and performance for many tasks.\n",
        "Use Case: Works well for text generation and summarization tasks, making it suitable for text normalization tasks where a transformation is needed.\n",
        "\n",
        "3. **mT5 (Multilingual T5)**\n",
        "\n",
        "* Model: google/mt5-small\n",
        "* Description: mT5 is a multilingual version of T5, designed to handle a wide variety of languages. It applies the same text-to-text framework as T5 but is trained on multiple languages, making it ideal for multilingual NLP tasks. It supports over 100 languages.\n",
        "* Size: The mT5-small variant has around 60 million parameters, making it lightweight and efficient while being multilingual.\n",
        "Use Case: Ideal for text normalization tasks involving multiple languages or when working with non-English datasets.\n"
      ],
      "metadata": {
        "id": "Jk9Fk8kxpm5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\"t5-small\", \"facebook/bart-base\", \"google/mt5-small\"]\n",
        "\n",
        "# Initialize the tokenizer and model from HuggingFace\n",
        "model_name = models[1]\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "batch_size = 8"
      ],
      "metadata": {
        "id": "h_Zp0vYmpMyo"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PyTorch dataset\n",
        "class TextNormalizationDataset(Dataset):\n",
        "    def __init__(self, inputs, targets, tokenizer, max_len=128):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        input_text = self.inputs[item]\n",
        "        target_text = self.targets[item]\n",
        "\n",
        "        # Tokenize the inputs and targets\n",
        "        input_encoding = self.tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
        "        target_encoding = self.tokenizer(target_text, padding=\"max_length\", truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
        "\n",
        "        # Extract the necessary values from the tokenization process\n",
        "        item = {\n",
        "            \"input_ids\": input_encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": input_encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": target_encoding[\"input_ids\"].squeeze(0),\n",
        "        }\n",
        "\n",
        "        # Move tensors to device (GPU or CPU)\n",
        "        item[\"input_ids\"] = item[\"input_ids\"].to(device)\n",
        "        item[\"attention_mask\"] = item[\"attention_mask\"].to(device)\n",
        "        item[\"labels\"] = item[\"labels\"].to(device)\n",
        "\n",
        "        return item\n",
        "\n",
        "# Create the data loaders\n",
        "train_dataset = TextNormalizationDataset(train_inputs, train_targets, tokenizer)\n",
        "val_dataset = TextNormalizationDataset(val_inputs, val_targets, tokenizer)\n",
        "test_dataset = TextNormalizationDataset(test_inputs, test_targets, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "POvF1ez5hXKJ"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Model & Optimizer"
      ],
      "metadata": {
        "id": "yKXTkLEBhZqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model for sequence-to-sequence tasks\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Set up optimizer and loss function\n",
        "learning_rate = 5e-5\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "kshJDW81hcKB"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "YQbCCTQBhmOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training and validation time\n",
        "start_train_val_time = time.time()\n",
        "\n",
        "# Training and validation loop\n",
        "epochs = 6\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\")\n",
        "\n",
        "    # Training phase\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move data to device (GPU/CPU)\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update progress bar with the current loss\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():  # No gradient computation for validation\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            # Move validation data to device\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "    # Print training and validation loss for the epoch\n",
        "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss / len(train_loader):.2f}, Validation Loss: {val_loss / len(val_loader):.2f}\")\n",
        "\n",
        "# End of training and validation time\n",
        "end_train_val_time = time.time()\n",
        "train_val_elapsed_time = end_train_val_time - start_train_val_time\n",
        "print(f\"Training and Validation Time: {train_val_elapsed_time / 60:.2f} minutes\")"
      ],
      "metadata": {
        "id": "WeRrmX3uhpoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa34d8a-87c0-4d3e-f045-fa1bea9e2c76"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 875/875 [04:54<00:00,  2.97it/s, loss=0.00893]\n",
            "Validating: 100%|██████████| 188/188 [00:18<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.42, Validation Loss: 0.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2: 100%|██████████| 875/875 [04:49<00:00,  3.02it/s, loss=0.0247]\n",
            "Validating: 100%|██████████| 188/188 [00:18<00:00, 10.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.03, Validation Loss: 0.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3: 100%|██████████| 875/875 [04:49<00:00,  3.02it/s, loss=0.0234]\n",
            "Validating: 100%|██████████| 188/188 [00:18<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.03, Validation Loss: 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4: 100%|██████████| 875/875 [04:49<00:00,  3.02it/s, loss=0.00718]\n",
            "Validating: 100%|██████████| 188/188 [00:18<00:00, 10.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss: 0.02, Validation Loss: 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5: 100%|██████████| 875/875 [04:49<00:00,  3.02it/s, loss=0.034]\n",
            "Validating: 100%|██████████| 188/188 [00:18<00:00, 10.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.02, Validation Loss: 0.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 6: 100%|██████████| 875/875 [04:49<00:00,  3.02it/s, loss=0.0234]\n",
            "Validating: 100%|██████████| 188/188 [00:19<00:00,  9.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss: 0.02, Validation Loss: 0.03\n",
            "Training and Validation Time: 30.89 minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation on Test Set"
      ],
      "metadata": {
        "id": "-VOGU3WwiT_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start evaluation time\n",
        "eval_start_time = time.time()\n",
        "\n",
        "test_predictions = []\n",
        "test_references = []\n",
        "model.eval()\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "rouge = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "\n",
        "exact_match_count = 0\n",
        "total_count = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating on Test Set\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        # Generate predictions\n",
        "        outputs = model.generate(input_ids, max_length=128)\n",
        "        predictions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "        references = [tokenizer.decode(label, skip_special_tokens=True) for label in labels]\n",
        "\n",
        "        test_predictions.extend(predictions)\n",
        "        test_references.extend(references)\n",
        "\n",
        "        # Exact Match (EM)\n",
        "        for pred, ref in zip(predictions, references):\n",
        "            total_count += 1\n",
        "            if pred.strip() == ref.strip():\n",
        "                exact_match_count += 1\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(test_references, test_predictions)\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = np.mean([sentence_bleu([ref.split()], pred.split()) for ref, pred in zip(test_references, test_predictions)])\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "rouge1 = np.mean([rouge.score(ref, pred)[\"rouge1\"].fmeasure for ref, pred in zip(test_references, test_predictions)])\n",
        "rouge2 = np.mean([rouge.score(ref, pred)[\"rouge2\"].fmeasure for ref, pred in zip(test_references, test_predictions)])\n",
        "rougeL = np.mean([rouge.score(ref, pred)[\"rougeL\"].fmeasure for ref, pred in zip(test_references, test_predictions)])\n",
        "\n",
        "# Calculate Jaro-Winkler similarity\n",
        "jaro_winkler_scores = np.mean([jaro_winkler_similarity(ref, pred) for ref, pred in zip(test_references, test_predictions)])\n",
        "\n",
        "# Calculate Word Error Rate (WER)\n",
        "wer_score = np.mean([wer(ref, pred) for ref, pred in zip(test_references, test_predictions)])\n",
        "\n",
        "# Calculate Character Error Rate (CER)\n",
        "cer_score = np.mean([cer(ref, pred) for ref, pred in zip(test_references, test_predictions)])\n",
        "\n",
        "# Calculate Exact Match (EM)\n",
        "exact_match = exact_match_count / total_count\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Test BLEU Score: {bleu_score:.2f}\")\n",
        "print(f\"Test ROUGE-1 Score: {rouge1:.2f}\")\n",
        "print(f\"Test ROUGE-2 Score: {rouge2:.2f}\")\n",
        "print(f\"Test ROUGE-L Score: {rougeL:.2f}\")\n",
        "print(f\"Test Jaro-Winkler Score: {jaro_winkler_scores:.2f}\")\n",
        "print(f\"Test WER: {wer_score:.2f}\")\n",
        "print(f\"Test CER: {cer_score:.2f}\")\n",
        "print(f\"Test Exact Match: {exact_match:.2f}\")\n",
        "\n",
        "# End evaluation time\n",
        "eval_end_time = time.time()\n",
        "eval_elapsed_time = eval_end_time - eval_start_time\n",
        "print(f\"Evaluation Time: {eval_elapsed_time / 60:.2f} minutes\")"
      ],
      "metadata": {
        "id": "5y3FpW6wh17K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bda7a277-40cb-4810-89e4-d89e5adab6d9"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating on Test Set: 100%|██████████| 188/188 [01:13<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.71\n",
            "Test BLEU Score: 0.14\n",
            "Test ROUGE-1 Score: 0.79\n",
            "Test ROUGE-2 Score: 0.63\n",
            "Test ROUGE-L Score: 0.79\n",
            "Test Jaro-Winkler Score: 0.93\n",
            "Test WER: 0.49\n",
            "Test CER: 0.78\n",
            "Test Exact Match: 0.71\n",
            "Evaluation Time: 1.24 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Total Notebook Execution Time"
      ],
      "metadata": {
        "id": "hP10gHS6idFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Record the end time and calculate the total execution time\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(f\"Total Execution Time: {execution_time / 60:.2f} minutes\")"
      ],
      "metadata": {
        "id": "0mk5gLUBicLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad922db-e3dc-459f-d4b0-32ed7262488a"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Execution Time: 32.28 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Results"
      ],
      "metadata": {
        "id": "QFvVLnNcngM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "# Format the metrics to 2 decimal places for numeric values\n",
        "metrics = {\n",
        "    \"timestamp\": timestamp,\n",
        "    \"gpu_used\": device!=\"cpu\",\n",
        "    \"model_name\": model_name,\n",
        "    \"epochs\": epochs,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"accuracy\": round(accuracy, 2),\n",
        "    \"bleu_score\": round(bleu_score, 2),\n",
        "    \"rouge1\": round(rouge1, 2),\n",
        "    \"rouge2\": round(rouge2, 2),\n",
        "    \"rougeL\": round(rougeL, 2),\n",
        "    \"jaro_winkler_score\": round(jaro_winkler_scores, 2),\n",
        "    \"wer\": round(wer_score, 2),\n",
        "    \"cer\": round(cer_score, 2),\n",
        "    \"exact_match\": round(exact_match, 2),\n",
        "    \"total_notebook_time\": int(execution_time / 60)\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "metrics_df = pd.DataFrame([metrics])\n",
        "\n",
        "# Read existing CSV if it exists, otherwise create a new one\n",
        "csv_file = '/content/drive/My Drive/JobSeeking/Orfium/finetuning_results.csv'\n",
        "try:\n",
        "    existing_df = pd.read_csv(csv_file)\n",
        "    updated_df = pd.concat([existing_df, metrics_df], ignore_index=True)\n",
        "except FileNotFoundError:\n",
        "    # If the file doesn't exist, create a new CSV with the metrics\n",
        "    updated_df = metrics_df\n",
        "\n",
        "# Save the results to the CSV file\n",
        "updated_df.to_csv(csv_file, index=False)\n",
        "display(updated_df)"
      ],
      "metadata": {
        "id": "lFUoOQqxnLZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "28abade5-6c0e-4214-b9ca-5c8e223fff77"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             timestamp  gpu_used          model_name  epochs  learning_rate  \\\n",
              "0  2025-01-02 10:09:10      True            t5-small       3        0.00005   \n",
              "1  2025-01-02 10:28:24      True  facebook/bart-base       3        0.00005   \n",
              "2  2025-01-02 10:53:02      True    google/mt5-small       3        0.00005   \n",
              "3  2025-01-02 11:26:52      True  facebook/bart-base       6        0.00005   \n",
              "\n",
              "   batch_size  accuracy  bleu_score  rouge1  rouge2  rougeL  \\\n",
              "0           8      0.66        0.16    0.73    0.64    0.73   \n",
              "1           8      0.72        0.15    0.79    0.64    0.79   \n",
              "2           8      0.00        0.00    0.00    0.00    0.00   \n",
              "3           8      0.71        0.14    0.79    0.63    0.79   \n",
              "\n",
              "   jaro_winkler_score   wer   cer  exact_match  total_notebook_time  \n",
              "0                0.87  0.71  0.97         0.66                   10  \n",
              "1                0.93  0.58  0.81         0.72                   17  \n",
              "2                0.41  1.00  1.36         0.00                   23  \n",
              "3                0.93  0.49  0.78         0.71                   32  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0fe2ca5-60c9-49d1-8c26-cc312e131ee4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>gpu_used</th>\n",
              "      <th>model_name</th>\n",
              "      <th>epochs</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>bleu_score</th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>jaro_winkler_score</th>\n",
              "      <th>wer</th>\n",
              "      <th>cer</th>\n",
              "      <th>exact_match</th>\n",
              "      <th>total_notebook_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-01-02 10:09:10</td>\n",
              "      <td>True</td>\n",
              "      <td>t5-small</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>8</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.66</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-01-02 10:28:24</td>\n",
              "      <td>True</td>\n",
              "      <td>facebook/bart-base</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>8</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.72</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-01-02 10:53:02</td>\n",
              "      <td>True</td>\n",
              "      <td>google/mt5-small</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-01-02 11:26:52</td>\n",
              "      <td>True</td>\n",
              "      <td>facebook/bart-base</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>8</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.71</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0fe2ca5-60c9-49d1-8c26-cc312e131ee4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f0fe2ca5-60c9-49d1-8c26-cc312e131ee4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f0fe2ca5-60c9-49d1-8c26-cc312e131ee4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-41c645f3-8a8c-4696-9d28-c745d6fb71f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41c645f3-8a8c-4696-9d28-c745d6fb71f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-41c645f3-8a8c-4696-9d28-c745d6fb71f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a373f7ed-a45e-48cb-8375-c330c42e28f3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('updated_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a373f7ed-a45e-48cb-8375-c330c42e28f3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('updated_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "updated_df",
              "summary": "{\n  \"name\": \"updated_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2025-01-02 10:28:24\",\n          \"2025-01-02 11:26:52\",\n          \"2025-01-02 10:09:10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gpu_used\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"t5-small\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5e-05,\n        \"max\": 5e-05,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34932076949417135,\n        \"min\": 0.0,\n        \"max\": 0.72,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07544313531837517,\n        \"min\": 0.0,\n        \"max\": 0.16,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3860375629391523,\n        \"min\": 0.0,\n        \"max\": 0.79,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3183682354339599,\n        \"min\": 0.0,\n        \"max\": 0.64,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3860375629391523,\n        \"min\": 0.0,\n        \"max\": 0.79,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jaro_winkler_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25159491250818256,\n        \"min\": 0.41,\n        \"max\": 0.93,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2224859546128699,\n        \"min\": 0.49,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26670833007863354,\n        \"min\": 0.78,\n        \"max\": 1.36,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exact_match\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34932076949417135,\n        \"min\": 0.0,\n        \"max\": 0.72,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_notebook_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 10,\n        \"max\": 32,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# csv_file = '/content/drive/My Drive/JobSeeking/Orfium/finetuning_results.csv'\n",
        "# if os.path.exists(csv_file):\n",
        "#   os.remove(csv_file)\n",
        "#   print(f\"File '{csv_file}' deleted successfully.\")\n",
        "# else:\n",
        "#   print(f\"File '{csv_file}' not found.\")"
      ],
      "metadata": {
        "id": "tqopzQamOAld"
      },
      "execution_count": 150,
      "outputs": []
    }
  ]
}